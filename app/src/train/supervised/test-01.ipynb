{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import kornia as K\n",
    "from PIL import Image\n",
    "\n",
    "hf_dataset = load_dataset(\"blanchon/UC_Merced\", split= \"train\")\n",
    "# ucmerced_test = load_dataset(\"blanchon/UC_Merced\", split= \"train[80%:]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcess(torch.nn.Module):\n",
    "    \"\"\"Module to perform pre-process using Kornia on torch tensors.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    " \n",
    "    @torch.no_grad()  # disable gradients for effiency\n",
    "    def forward(self, x: Image) -> torch.Tensor:\n",
    "        x_tmp: np.ndarray = np.array(x)  # HxWxC\n",
    "        x_out: torch.Tensor = K.image_to_tensor(x_tmp, keepdim=True)  # CxHxW\n",
    "        return x_out.float() / 255.0\n",
    "\n",
    "train_transforms = torch.nn.Sequential(\n",
    "    PreProcess(),\n",
    "    K.augmentation.Resize(size=224, side=\"short\"),\n",
    "    K.augmentation.CenterCrop(size=224),\n",
    "    K.augmentation.RandomHorizontalFlip(p=0.5),\n",
    "    K.augmentation.ColorJiggle(),\n",
    "    K.augmentation.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    ")\n",
    "\n",
    "val_transforms = torch.nn.Sequential(\n",
    "    PreProcess(),\n",
    "    K.augmentation.Resize(size=224, side=\"short\"),\n",
    "    K.augmentation.CenterCrop(size=224),\n",
    "    K.augmentation.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    ")\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"image\"] = [train_transforms(image).squeeze() for image in example_batch[\"image\"]]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"image\"] = [val_transforms(image).squeeze() for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset.set_transform(preprocess_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(hf_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch['image'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hf_dataset.features[\"label\"].names\n",
    "print(\"ALL LABELS\")\n",
    "print(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "print(\"\\nALL LABELS to ID\")\n",
    "print(label2id)\n",
    "print(\"\\nALL ID to LABELS\")\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect an example\n",
    "dataset[0][0].shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
